{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"2. Implementing an update function\"\n",
    "---\n",
    "\n",
    "First, we need to create a function that implements the core update method for our model (i.e., how it updates its value estimate in response to the outcomes it has received).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "First, we import necessary packages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## The Rescorla-Wagner update rule\n",
    "\n",
    "In the standard Rescorla-Wagner model, this occurs as follows:\n",
    "\n",
    "$$V_{t+1} = V_t + \\alpha \\times \\delta_t$$\n",
    "\n",
    "where $V_{t+1}$ is the value estimate at time $t+1$, $V_t$ is the value estimate at time $t$, $\\alpha$ is the learning rate, and $\\delta_t$ is the prediction error at time $t$.\n",
    "\n",
    "The prediction error $$\\delta_t$$ is calculated as the difference between the reward received at time $t$ and the value estimate at time $t$:\n",
    "\n",
    "$$\\delta_t = R_t - V_t$$\n",
    "\n",
    "where $R_t$ is the reward received at time $t$.\n",
    "\n",
    "## Introducing asymmetry\n",
    "\n",
    "We can introduce asymmetry into the model by allowing the learning rate to be different for positive and negative prediction errors. This can be implemented as follows. Our prediction error is calculated as normal:\n",
    "\n",
    "$$\\delta_t = R_t - V_t$$\n",
    "\n",
    "But we now choose our learning rate for the current trial $\\alpha_t$ based on the sign of the prediction error:\n",
    "\n",
    "$$\\alpha_t = \\alpha^+ \\text{ if } \\delta_t > 0 \\text{ else } \\alpha^-$$\n",
    "\n",
    "where $\\alpha^+$ is the learning rate for positive prediction errors, and $\\alpha^-$ is the learning rate for negative prediction errors. The update rule then becomes:\n",
    "\n",
    "$$V_{t+1} = V_t + \\alpha_t \\times \\delta_t$$\n",
    "\n",
    "## The update function\n",
    "\n",
    "We can implement this in JAX as follows:\n",
    "\n",
    "> Note: We will use the `@jit` decorator to compile the function for faster execution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def asymmetric_rescorla_wagner_update(\n",
    "    value: float, outcome: float, alpha_p: float, alpha_n: float\n",
    ") -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Updates the estimated value of a state or action using the Asymmetric Rescorla-Wagner learning rule.\n",
    "\n",
    "    The function calculates the prediction error as the difference between the actual outcome and the current\n",
    "    estimated value. It then updates the estimated value based on the prediction error and the learning rate,\n",
    "    which is determined by whether the prediction error is positive or negative.\n",
    "\n",
    "    Args:\n",
    "        value (float): The current estimated value of a state or action.\n",
    "        outcome (float): The actual reward received.\n",
    "        alpha_p (float): The learning rate used when the prediction error is positive.\n",
    "        alpha_n (float): The learning rate used when the prediction error is negative.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[float, float]: The updated value and the prediction error.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate the prediction error\n",
    "    prediction_error = outcome - value\n",
    "\n",
    "    # Set the learning rate based on the sign of the prediction error\n",
    "    # Remember - we can't use if else statements here because JAX doesn't tolerate them\n",
    "    alpha_t = (alpha_p * (prediction_error > 0)) + (alpha_n * (prediction_error < 0))\n",
    "\n",
    "    # Update the value\n",
    "    value = value + alpha_t * prediction_error\n",
    "\n",
    "    return value, prediction_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few things to note about this implementation:\n",
    "\n",
    "-   **No if/else statements**: As mentioned in [this guide](/docs/computational_modelling/guide/1.-building-basic-models#other-things-to-watch-out-for-with-jax), we can't use if/else statements in JAX. Instead, we create binary variables that we can use to determine the learning rate through multiplication.\n",
    "-   **Return values**: We return both the value estimate and the prediction error. The value estimate is critical for our model as this is the key quantity we're estimating. The prediction error isn't vital, but can be useful to return (e.g., we might want to plot it later or link it to neural activity).\n",
    "-   **Docstring**: We use a docstring to describe the function. This is good practice as it helps others understand what the function does. I like to use [Google format](https://sphinxcontrib-napoleon.readthedocs.io/en/latest/example_google.html) for docstrings.\n",
    "-   **Type hints**: We use type hints to specify the types of the inputs and outputs. This is good practice as it helps others understand what the function expects and returns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking that the functon works\n",
    "\n",
    "If all is well with our implementation, we should be able to run the function and get some output. Let's test this now.\n",
    "\n",
    "We'll set $\\alpha_p$ to a low value and $\\alpha_n$ to a high value, so we can see how the value estimate changes in response to positive and negative prediction errors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Value: 0.55\n",
      "Prediction Error: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Initialize the value, outcome, and learning rates\n",
    "value = 0.5\n",
    "outcome = 1.0\n",
    "alpha_p = 0.1\n",
    "alpha_n = 0.9\n",
    "\n",
    "# Call the function\n",
    "updated_value, prediction_error = asymmetric_rescorla_wagner_update(\n",
    "    value, outcome, alpha_p, alpha_n\n",
    ")\n",
    "\n",
    "# Print the results\n",
    "print(f\"Updated Value: {updated_value}\")\n",
    "print(f\"Prediction Error: {prediction_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we have a positive prediction error and we can see that the value estimate increases by a small amount, as the learning rate for positive prediction errors is low.\n",
    "\n",
    "Let's see what happens if we have a negative prediction error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Value: 0.04999999999999999\n",
      "Prediction Error: -0.5\n"
     ]
    }
   ],
   "source": [
    "# Initialize the value, outcome, and learning rates\n",
    "value = 0.5\n",
    "outcome = 0\n",
    "alpha_p = 0.1\n",
    "alpha_n = 0.9\n",
    "\n",
    "# Call the function\n",
    "updated_value, prediction_error = asymmetric_rescorla_wagner_update(\n",
    "    value, outcome, alpha_p, alpha_n\n",
    ")\n",
    "\n",
    "# Print the results\n",
    "print(f\"Updated Value: {updated_value}\")\n",
    "print(f\"Prediction Error: {prediction_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our estimated value has gone from 0.55 to 0.05 (there's a bit of a precision issue here, but it's close enough). This is because the learning rate for negative prediction errors is high, so the value estimate has decreased by a large amount.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with arrays\n",
    "\n",
    "Our function can also be applied to arrays. This is useful if we have multiple stimuli/actions that people are learning the value of. We can pass in an array of value estimates and rewards, and get back an array of updated value estimates and prediction errors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Value: [0.55 0.05 0.55 0.05 0.55]\n",
      "Prediction Error: [ 0.5 -0.5  0.5 -0.5  0.5]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the value, outcome, and learning rates\n",
    "value = np.ones(5) * 0.5\n",
    "outcome = np.array([1.0, 0.0, 1.0, 0.0, 1.0])\n",
    "alpha_p = 0.1\n",
    "alpha_n = 0.9\n",
    "\n",
    "# Call the function\n",
    "updated_value, prediction_error = asymmetric_rescorla_wagner_update(\n",
    "    value, outcome, alpha_p, alpha_n\n",
    ")\n",
    "\n",
    "# Print the results\n",
    "print(f\"Updated Value: {updated_value}\")\n",
    "print(f\"Prediction Error: {prediction_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making our function more flexible\n",
    "\n",
    "It's quite common in learning tasks that people have to estimate the value of multiple stimuli or actions, but only receive feedback for their chosen option on any given trial. Currently, our function will update the value estimate for all stimuli/actions on every trial, which isn't necessarily what we want to do.\n",
    "\n",
    "We can make our function more flexible by allowing it to update only the value estimate for the chosen option. We can do this by passing in an additional argument that specifies which option was chosen on the current trial. We'll also update the type hints so that they make it clear we can pass in arrays of value estimates and rewards.\n",
    "\n",
    "> **Note**: We use the `jax.typing.ArrayLike` type hint to specify that the input is an array-like object (e.g., a list, tuple, or JAX array). This is useful as it makes it clear that the user can pass in different types of array-like objects (e.g., lists or JAX arrays).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def asymmetric_rescorla_wagner_update(\n",
    "    value: jax.typing.ArrayLike,\n",
    "    outcome: jax.typing.ArrayLike,\n",
    "    chosen: jax.typing.ArrayLike,\n",
    "    alpha_p: float,\n",
    "    alpha_n: float,\n",
    ") -> Tuple[jax.typing.ArrayLike, jax.typing.ArrayLike]:\n",
    "    \"\"\"\n",
    "    Updates the estimated value of a state or action using the Asymmetric Rescorla-Wagner learning rule.\n",
    "\n",
    "    The function calculates the prediction error as the difference between the actual outcome and the current\n",
    "    estimated value. It then updates the estimated value based on the prediction error and the learning rate,\n",
    "    which is determined by whether the prediction error is positive or negative.\n",
    "\n",
    "    Value estimates are only updated for chosen actions. For unchosen actions, the prediction error is set to 0.\n",
    "\n",
    "    Args:\n",
    "        value (float): The current estimated value of a state or action.\n",
    "        outcome (float): The actual reward received.\n",
    "        chosen (float): Binary indicator of whether the action was chosen (1) or not (0).\n",
    "        alpha_p (float): The learning rate used when the prediction error is positive.\n",
    "        alpha_n (float): The learning rate used when the prediction error is negative.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[float, float]: The updated value and the prediction error.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate the prediction error\n",
    "    prediction_error = outcome - value\n",
    "\n",
    "    # Set prediction error to 0 for unchosen actions\n",
    "    prediction_error = prediction_error * chosen\n",
    "\n",
    "    # Set the learning rate based on the sign of the prediction error\n",
    "    # Remember - we can't use if else statements here because JAX doesn't tolerate them\n",
    "    alpha_t = (alpha_p * (prediction_error > 0)) + (alpha_n * (prediction_error < 0))\n",
    "\n",
    "    # Update the value\n",
    "    value = value + alpha_t * prediction_error\n",
    "\n",
    "    return value, prediction_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we've incorporated information about which option was chosen by multiplying the prediction error by a binary variable that is 1 if the option was chosen and 0 otherwise. This means that the value estimate for the chosen option will be updated, while the value estimates for the other options will remain the same.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Value: [0.55       0.05000001 0.5        0.5        0.5       ]\n",
      "Prediction Error: [ 0.5 -0.5  0.  -0.   0. ]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the value, outcome, choices, and learning rates\n",
    "value = np.ones(5) * 0.5\n",
    "outcome = np.array([1.0, 0.0, 1.0, 0.0, 1.0])\n",
    "chosen = np.array([1, 1, 0, 0, 0])\n",
    "alpha_p = 0.1\n",
    "alpha_n = 0.9\n",
    "\n",
    "# Call the function\n",
    "updated_value, prediction_error = asymmetric_rescorla_wagner_update(\n",
    "    value, outcome, chosen, alpha_p, alpha_n\n",
    ")\n",
    "\n",
    "# Print the results\n",
    "print(f\"Updated Value: {updated_value}\")\n",
    "print(f\"Prediction Error: {prediction_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that only the values for the chosen options have been updated, while the rest remain at 0.5."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "windows_general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
