{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"3. Selecting actions\"\n",
    "---\n",
    "\n",
    "# Selecting actions\n",
    "\n",
    "In most learning tasks we are asking participants to _select_ different actions or stimuli based on their estimated value. This means that our model not only needs to estimate the value of different options, but also make choices.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "First, we import necessary packages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Softmax function\n",
    "\n",
    "The softmax function is a common way to convert values into choice probabilities. It is defined as:\n",
    "\n",
    "$$\n",
    "P(a) = \\frac{e^{Q(a) / \\tau}}{\\sum_{a'} e^{Q(a') / \\tau}}\n",
    "$$\n",
    "\n",
    "where $Q(a)$ is the value of action $a$, and $\\tau$ is a parameter that controls the randomness of the choices (referred to as a _temperature_ parameter). When $\\tau$ is high, the softmax function will output similar probabilities for all actions, while when $\\tau$ is low, the softmax function will output probabilities that are close to 0 or 1.\n",
    "\n",
    "Essentially, the softmax function calculates the probability of a given action based on its value relative to the values of all other actions. The higher the value of an action, the higher its probability of being selected.\n",
    "\n",
    "For the sake of simplicity and reproducibility, we'll use an existing implementation of the softmax function from the `behavioural_modelling` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m     \n",
      "\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_typing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_array_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SupportsArray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_typing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_sequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NestedSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_typing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_array_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SupportsArray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomplex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_typing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_sequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NestedSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomplex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtemperature\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_typing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_array_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SupportsArray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_typing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_sequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NestedSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_typing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_array_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SupportsArray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomplex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_typing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_sequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NestedSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomplex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCall signature:\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mType:\u001b[0m           PjitFunction\n",
      "\u001b[0;31mString form:\u001b[0m    <PjitFunction of <function softmax at 0x7f16777c3be0>>\n",
      "\u001b[0;31mFile:\u001b[0m           ~/miniconda3/envs/transition_uncertainty/lib/python3.10/site-packages/behavioural_modelling/decision_rules.py\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "Softmax function, with optional temperature parameter.\n",
      "\n",
      "Args:\n",
      "    value (ArrayLike): Array of values to apply softmax to, of shape (n_trials, n_bandits)\n",
      "    temperature (float, optional): Softmax temperature, in range 0 > inf. Defaults to 1.\n",
      "\n",
      "Returns:\n",
      "    ArrayLike: Choice probabilities, of shape (n_trials, n_bandits)"
     ]
    }
   ],
   "source": [
    "from behavioural_modelling.decision_rules import softmax\n",
    "\n",
    "?softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstrating the softmax function\n",
    "\n",
    "To demonstrate, we can provide a set of action values and calculate the probabilities of selecting each action according to different temperature parameter values.\n",
    "\n",
    "> **NOTE**: The function expects our values to be 2-dimensional, as we'll often want to apply it to a a set of values for multiple stimuli across multiple trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature: 0.1\n",
      "[[0. 1. 0.]]\n",
      "Temperature: 0.5\n",
      "[[0.12 0.87 0.02]]\n",
      "Temperature: 0.9\n",
      "[[0.22999999 0.7        0.08      ]]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the values\n",
    "values = jnp.array([[2.0, 3.0, 1.0]])\n",
    "\n",
    "# Example temperature parameter values\n",
    "temperature = [0.1, 0.5, 0.9]\n",
    "\n",
    "# Compute the softmax probabilities using each temperature parameter\n",
    "for t in temperature:\n",
    "    print(f\"Temperature: {t}\")\n",
    "    print(np.round(softmax(values, t), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing an action\n",
    "\n",
    "We also want to actually choose an action based on these estimated probabilities. Again, we'll use an existing function for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m     \n",
      "\u001b[0mchoice_from_action_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0mfunction\u001b[0m \u001b[0mPRNGKey\u001b[0m \u001b[0mat\u001b[0m \u001b[0;36m0x7f160e170700\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mprobs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_typing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_array_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SupportsArray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_typing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_sequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NestedSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_typing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_array_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SupportsArray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomplex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_typing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_sequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NestedSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomplex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mlapse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCall signature:\u001b[0m \u001b[0mchoice_from_action_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mType:\u001b[0m           PjitFunction\n",
      "\u001b[0;31mString form:\u001b[0m    <PjitFunction of <function choice_from_action_p at 0x7f15fc730310>>\n",
      "\u001b[0;31mFile:\u001b[0m           ~/miniconda3/envs/transition_uncertainty/lib/python3.10/site-packages/behavioural_modelling/utils.py\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "Choose an action from a set of action probabilities. Can take probabilities\n",
      "in the form of an n-dimensional array, where the last dimension is the\n",
      "number of actions.\n",
      "\n",
      "Noise is added to the choice, with probability `lapse`. This means that\n",
      "on \"lapse\" trials, the subject will choose an action uniformly at random.\n",
      "\n",
      "Args:\n",
      "    key (int): Jax random key\n",
      "    probs (np.ndarray): N-dimension array of action probabilities, of shape (..., n_actions)\n",
      "    lapse (float, optional): Probability of lapse. Defaults to 0.0.\n",
      "Returns:\n",
      "    int: Chosen action"
     ]
    }
   ],
   "source": [
    "from behavioural_modelling.utils import choice_from_action_p\n",
    "\n",
    "?choice_from_action_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incorporating randomness\n",
    "\n",
    "We want to make sure our choices are not deterministic: if we have an action probability of 0.75 this means we'll only want to choose this action 75% of the time. JAX is a little complex when it comes to randomness, and you need to supply a random \"key\" every time you want to generate random numbers. This means that when using this function for choosing actions, you'll need to pass in a key as well.\n",
    "\n",
    "Because we're supplying a random key, the function will **always** return the same action when is given the same key. This is useful for reproducibility, but it also means that you'll need to pass in a new key every time you want to generate a new action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([1], dtype=int32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a random key\n",
    "key = jax.random.PRNGKey(0)\n",
    "\n",
    "# Choose an action using the softmax probabilities\n",
    "choice_from_action_p(key, softmax(values, t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incorporating the softmax function into our model\n",
    "\n",
    "As it stands, we've implemented a model that can estimate the value of different actions. However, we haven't yet implemented a way to select actions based on these values. We can do this by incorporating the softmax function into our model.\n",
    "\n",
    "In order to keep our code as modular as possible, we will create a new function (`asymmetric_rescorla_wagner_update_choice`) that will use our existing update function to estimate the value of different actions, and then use the softmax function to select an action based on these values, rather than integrating this functionality directly into our existing update function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS OUR EXISTING UPDATE FUNCTION\n",
    "@jax.jit\n",
    "def asymmetric_rescorla_wagner_update(\n",
    "    value: jax.typing.ArrayLike,\n",
    "    outcome: jax.typing.ArrayLike,\n",
    "    chosen: jax.typing.ArrayLike,\n",
    "    alpha_p: float,\n",
    "    alpha_n: float,\n",
    ") -> Tuple[jax.typing.ArrayLike, jax.typing.ArrayLike]:\n",
    "    \"\"\"\n",
    "    Updates the estimated value of a state or action using the Asymmetric Rescorla-Wagner learning rule.\n",
    "\n",
    "    The function calculates the prediction error as the difference between the actual outcome and the current\n",
    "    estimated value. It then updates the estimated value based on the prediction error and the learning rate,\n",
    "    which is determined by whether the prediction error is positive or negative.\n",
    "\n",
    "    Value estimates are only updated for chosen actions. For unchosen actions, the prediction error is set to 0.\n",
    "\n",
    "    Args:\n",
    "        value (float): The current estimated value of a state or action.\n",
    "        outcome (float): The actual reward received.\n",
    "        chosen (float): Binary indicator of whether the action was chosen (1) or not (0).\n",
    "        alpha_p (float): The learning rate used when the prediction error is positive.\n",
    "        alpha_n (float): The learning rate used when the prediction error is negative.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[float, float]: The updated value and the prediction error.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate the prediction error\n",
    "    prediction_error = outcome - value\n",
    "\n",
    "    # Set prediction error to 0 for unchosen actions\n",
    "    prediction_error = prediction_error * chosen\n",
    "\n",
    "    # Set the learning rate based on the sign of the prediction error\n",
    "    alpha_t = (alpha_p * (prediction_error > 0)) + (alpha_n * (prediction_error < 0))\n",
    "\n",
    "    # Update the value\n",
    "    value = value + alpha_t * prediction_error\n",
    "\n",
    "    return value, prediction_error\n",
    "\n",
    "# THIS IS OUR NEW CHOICE FUNCTION\n",
    "@jax.jit\n",
    "def asymmetric_rescorla_wagner_update_choice(\n",
    "    value: jax.typing.ArrayLike,\n",
    "    outcome: jax.typing.ArrayLike,\n",
    "    alpha_p: float,\n",
    "    alpha_n: float,\n",
    "    temperature: float,\n",
    "    n_actions: int,\n",
    "    key: jax.random.PRNGKey,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Updates the value estimate using the asymmetric Rescorla-Wagner algorithm, and chooses an\n",
    "    option based on the softmax function.\n",
    "\n",
    "    Args:\n",
    "        value (jax.typing.ArrayLike): The current value estimate.\n",
    "        outcome (jax.typing.ArrayLike): The outcome of the action.\n",
    "        alpha_p (float): The learning rate for positive outcomes.\n",
    "        alpha_n (float): The learning rate for negative outcomes.\n",
    "        temperature (float): The temperature parameter for softmax function.\n",
    "        n_actions (int): The number of actions to choose from.\n",
    "        key (jax.random.PRNGKey): The random key for the choice function.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[np.ndarray, Tuple[jax.typing.ArrayLike, np.ndarray, int, np.ndarray]]:\n",
    "            - updated_value (jnp.ndarray): The updated value estimate.\n",
    "            - output_tuple (Tuple[jax.typing.ArrayLike, np.ndarray, int, np.ndarray]):\n",
    "                - value (jax.typing.ArrayLike): The original value estimate.\n",
    "                - choice_p (jnp.ndarray): The choice probabilities.\n",
    "                - choice (int): The chosen action.\n",
    "                - choice_array (jnp.ndarray): The chosen action in one-hot format.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get choice probabilities\n",
    "    choice_p = softmax(value[None, :], temperature).squeeze()\n",
    "\n",
    "    # Get choice\n",
    "    choice = choice_from_action_p(key, choice_p)\n",
    "\n",
    "    # Convert it to one-hot format\n",
    "    choice_array = jnp.zeros(n_actions, dtype=jnp.int16)\n",
    "    choice_array = choice_array.at[choice].set(1)\n",
    "\n",
    "    # Get the outcome and update the value estimate\n",
    "    updated_value, prediction_error = asymmetric_rescorla_wagner_update(\n",
    "        value,\n",
    "        choice_array,\n",
    "        outcome,\n",
    "        alpha_p,\n",
    "        alpha_n,\n",
    "    )\n",
    "\n",
    "    return updated_value, (value, choice_p, choice_array, prediction_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is quite a lot going on here, so let's break it down.\n",
    "\n",
    "### 1. Inputs to the function\n",
    "\n",
    "```python\n",
    "def asymmetric_rescorla_wagner_update_choice(\n",
    "    value: jax.typing.ArrayLike,\n",
    "    outcome: jax.typing.ArrayLike,\n",
    "    chosen: jax.typing.ArrayLike,\n",
    "    alpha_p: float,\n",
    "    alpha_n: float,\n",
    "    temperature: float,\n",
    "    n_actions: int,\n",
    "    key: jax.random.PRNGKey,\n",
    ") -> np.ndarray:\n",
    "```\n",
    "As with our previous function, we provide the current value and the outcome received. Note that we don't need to provide the chosen option as we're generating this from scratch. We also provide the learning rates for positive and negative prediction errors and the temperature parameter for the softmax function.\n",
    "\n",
    "We also need to provide the number of possible actions. This is because we need to generate a one-hot array of the chosen action, and we need to know how long this array should be. **Why can we not just infer this from the length of the value array using e.g., `value.shape`?** This is because JAX needs to know the size of the array at compile time, and the size of the value array is not known until runtime. Otherwise, we will get an error when we try to compile the function.\n",
    "\n",
    "Finally, we need to provide a random key. This is because we're using JAX's random number generator to generate a random choice, and we need to provide a key to do this.\n",
    "\n",
    "\n",
    "### 2. Getting choice probabilities from values\n",
    "\n",
    "```python\n",
    "choice_p = softmax(value[None, :], temperature).squeeze()\n",
    "```\n",
    "\n",
    "As we mentioned earlier, the softmax function calculates the probability of selecting each action based on its value. We pass in our estimated values for each action, and the temperature parameter, and get back a set of probabilities for selecting each action.\n",
    "\n",
    "By default, the `softmax` function expects a 2-dimensional array of values, where the first dimension corresponds to the number of trials and the second dimension corresponds to the number of actions. However, our `value` array is 1-dimensional as it corresponds to the values or the current trial. We can use the `None` index to add an extra dimension to our array, and then `squeeze` to remove it again.\n",
    "\n",
    "> ⚠️ **Note**: It is important that we get choice probabilities and select actions **BEFORE** updating the value. When someone makes a choice on **Trial 1**, they are doing this without having received any information - their choice is based on their current expectation. Only after they have made a choice do they receive feedback, which is then used to update their expectation for the next trial.\n",
    "\n",
    "### 3. Choosing an action\n",
    "\n",
    "```python\n",
    "choice = choice_from_action_p(key, choice_p)\n",
    "```\n",
    "\n",
    "As we mentioned earlier, we need to pass in a random key in order to generate a random choice. We use the `choice_from_action_p` function to generate a random choice based on the probabilities we calculated using the softmax function.\n",
    "\n",
    "### 4. Converting to one-hot format\n",
    "\n",
    "```python\n",
    "choice_array = jnp.zeros(n_actions, dtype=jnp.int16)\n",
    "choice_array = choice_array.at[choice].set(1)\n",
    "```\n",
    "\n",
    "The `choice_from_action_p` function returns the index of the chosen action. We convert this index into a one-hot array, where all values are 0 except for the chosen action, which is 1. This is the format that our update function expects.\n",
    "\n",
    "### 5. Updating the estimated value\n",
    "\n",
    "```python\n",
    "updated_value = rescorla_wagner_update(\n",
    "    value,\n",
    "    choice_array,\n",
    "    outcomes,\n",
    "    alpha_p,\n",
    "    alpha_n,\n",
    ")\n",
    "```\n",
    "\n",
    "We now update our estimated value based on the chosen action and the outcome of that action. We use the `rescorla_wagner_update` function that we defined earlier to do this.\n",
    "\n",
    "### 6. Returning useful variables\n",
    "\n",
    "```python\n",
    "return updated_value, (value, choice_p, choice_array, prediction_error)\n",
    "```\n",
    "\n",
    "Finally, we return the updated value, as well as some other useful variables that we might want to keep track of, such as the choice probabilities, the one-hot array of the chosen action, and the prediction error.\n",
    "\n",
    "This might seem a little odd: **why do we return everything but `updated_value` as a tuple?** We could instead do something like:\n",
    "\n",
    "```python\n",
    "return updated_value, choice_p, choice_array, prediction_error\n",
    "```\n",
    "\n",
    "However, we will need to use this function within a `jax.lax.scan` loop, and `jax.lax.scan` expects the function to return only two values. The first value is what is fed back into the function at the next time step, and the second value is what is collected at each time step. The only variable that's going to be reused at the next time step is `updated_value`, so we return this as the first value, and everything else as the second value.\n",
    "\n",
    "There's something else here that's a bit confusing: **why do we return `value` as well as `updated_value`?** We don't actually need to return `value` here, as we're already returning `updated_value`. However, we might want to keep track of the value at each time step **before** it has been updated (e.g., perhaps we want to link expected value on a given trial to neural activity, in which case we want the value before it has been updated).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying out the function\n",
    "\n",
    "If we try to run our function as it's currently written, we will get an error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Shapes must be 1D sequences of concrete values of integer type, got (Traced<ShapedArray(int32[], weak_type=True)>with<DynamicJaxprTrace(level=1/0)>,).\nIf using `jit`, try using `static_argnums` or applying `jit` to smaller subfunctions.\nThe error occurred while tracing the function asymmetric_rescorla_wagner_update_choice at /tmp/ipykernel_38248/3994267310.py:45 for jit. This concrete value was not available in Python because it depends on the value of the argument n_actions.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m key \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mPRNGKey(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Call the function\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m updated_value, (value, choice_p, choice_array, prediction_error) \u001b[38;5;241m=\u001b[39m \u001b[43masymmetric_rescorla_wagner_update_choice\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutcome\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha_n\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Print the results\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpdated Value: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mupdated_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[43], line 85\u001b[0m, in \u001b[0;36masymmetric_rescorla_wagner_update_choice\u001b[0;34m(value, outcome, alpha_p, alpha_n, temperature, n_actions, key)\u001b[0m\n\u001b[1;32m     82\u001b[0m choice \u001b[38;5;241m=\u001b[39m choice_from_action_p(key, choice_p)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# Convert it to one-hot format\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m choice_array \u001b[38;5;241m=\u001b[39m \u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_actions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint16\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m choice_array \u001b[38;5;241m=\u001b[39m choice_array\u001b[38;5;241m.\u001b[39mat[choice]\u001b[38;5;241m.\u001b[39mset(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Get the outcome and update the value estimate\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/transition_uncertainty/lib/python3.10/site-packages/jax/_src/numpy/lax_numpy.py:2288\u001b[0m, in \u001b[0;36mzeros\u001b[0;34m(shape, dtype)\u001b[0m\n\u001b[1;32m   2286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (m \u001b[38;5;241m:=\u001b[39m _check_forgot_shape_tuple(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m, shape, dtype)): \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(m)\n\u001b[1;32m   2287\u001b[0m dtypes\u001b[38;5;241m.\u001b[39mcheck_user_dtype_supported(dtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2288\u001b[0m shape \u001b[38;5;241m=\u001b[39m \u001b[43mcanonicalize_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m lax\u001b[38;5;241m.\u001b[39mfull(shape, \u001b[38;5;241m0\u001b[39m, _jnp_dtype(dtype))\n",
      "File \u001b[0;32m~/miniconda3/envs/transition_uncertainty/lib/python3.10/site-packages/jax/_src/numpy/lax_numpy.py:80\u001b[0m, in \u001b[0;36mcanonicalize_shape\u001b[0;34m(shape, context)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcanonicalize_shape\u001b[39m(shape: Any, context: \u001b[38;5;28mstr\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m core\u001b[38;5;241m.\u001b[39mShape:\n\u001b[1;32m     78\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(shape, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m     79\u001b[0m       (\u001b[38;5;28mgetattr\u001b[39m(shape, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m ndim(shape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)):\n\u001b[0;32m---> 80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanonicalize_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     81\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m core\u001b[38;5;241m.\u001b[39mcanonicalize_shape(shape, context)\n",
      "File \u001b[0;32m~/miniconda3/envs/transition_uncertainty/lib/python3.10/site-packages/jax/_src/core.py:2130\u001b[0m, in \u001b[0;36mcanonicalize_shape\u001b[0;34m(shape, context)\u001b[0m\n\u001b[1;32m   2128\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   2129\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m-> 2130\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m _invalid_shape_error(shape, context)\n",
      "\u001b[0;31mTypeError\u001b[0m: Shapes must be 1D sequences of concrete values of integer type, got (Traced<ShapedArray(int32[], weak_type=True)>with<DynamicJaxprTrace(level=1/0)>,).\nIf using `jit`, try using `static_argnums` or applying `jit` to smaller subfunctions.\nThe error occurred while tracing the function asymmetric_rescorla_wagner_update_choice at /tmp/ipykernel_38248/3994267310.py:45 for jit. This concrete value was not available in Python because it depends on the value of the argument n_actions."
     ]
    }
   ],
   "source": [
    "# Initialize the value, outcome, choices, and learning rates\n",
    "value = np.ones(5) * 0.5\n",
    "outcome = np.array([1.0, 0.0, 1.0, 0.0, 1.0])\n",
    "alpha_p = 0.1\n",
    "alpha_n = 0.9\n",
    "temperature = 0.5\n",
    "\n",
    "# Get a random key\n",
    "key = jax.random.PRNGKey(0)\n",
    "\n",
    "# Call the function\n",
    "updated_value, (value, choice_p, choice_array, prediction_error) = asymmetric_rescorla_wagner_update_choice(\n",
    "    value, outcome, alpha_p, alpha_n, temperature, 5, key\n",
    ")\n",
    "\n",
    "# Print the results\n",
    "print(f\"Updated Value: {updated_value}\")\n",
    "print(f\"Prediction Error: {prediction_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are various clues in the error message as to what's gone wrong:\n",
    "\n",
    "` Shapes must be 1D sequences of concrete values of integer type, got (Traced<ShapedArray(int32[], weak_type=True)>with<DynamicJaxprTrace(level=1/0)>,).`\n",
    "\n",
    "`If using jit, try using static_argnums`\n",
    "\n",
    "`This concrete value was not available in Python because it depends on the value of the argument n_actions.`\n",
    "\n",
    "This is a common problem when using JAX - we need to provide the size of our arrays at compile time, but the size of our arrays is not known until runtime. \n",
    "\n",
    "### Using `static_argnums`\n",
    "\n",
    "Essentially, the problem is that JAX needs to know the shape of everything in advance - this is partly why it can make our code run so quickly. However, in this case, the size of the `choice_array` variable depends upon the `n_actions` variable, which is not known until runtime. We've supplied `5` here when calling the function, but all JAX sees is an integer that could take any value. \n",
    "\n",
    "The easiest solution is to tell JAX to compile the function so that it works _only_ with the value that we've passed in. So we'll get a compiled function that works for `n_actions=5`, but if we try to use it with `n_actions=10`, it will fail. This would mean that we need to recomplie the function every time we want to use it with a different number of actions, but in reality that isn't something we're likely to do.\n",
    "\n",
    "We can do this using the `static_argnums` argument to `jax.jit`. This tells JAX that the function should be compiled with respect to the arguments that we specify. In this case, we want to compile the function with respect to the `n_actions` argument, so we'll pass in `5` (the index of the `n_actions` argument in the function signature).\n",
    "\n",
    "> **NOTE**: We need to call `jax.jit()` as a function rather than using it as a decorator if we want to pass in `static_argnums`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asymmetric_rescorla_wagner_update_choice(\n",
    "    value: jax.typing.ArrayLike,\n",
    "    outcome: jax.typing.ArrayLike,\n",
    "    alpha_p: float,\n",
    "    alpha_n: float,\n",
    "    temperature: float,\n",
    "    n_actions: int,\n",
    "    key: jax.random.PRNGKey,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Updates the value estimate using the asymmetric Rescorla-Wagner algorithm, and chooses an\n",
    "    option based on the softmax function.\n",
    "\n",
    "    Args:\n",
    "        value (jax.typing.ArrayLike): The current value estimate.\n",
    "        outcome (jax.typing.ArrayLike): The outcome of the action.\n",
    "        alpha_p (float): The learning rate for positive outcomes.\n",
    "        alpha_n (float): The learning rate for negative outcomes.\n",
    "        temperature (float): The temperature parameter for softmax function.\n",
    "        n_actions (int): The number of actions to choose from.\n",
    "        key (jax.random.PRNGKey): The random key for the choice function.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[np.ndarray, Tuple[jax.typing.ArrayLike, np.ndarray, int, np.ndarray]]:\n",
    "            - updated_value (jnp.ndarray): The updated value estimate.\n",
    "            - output_tuple (Tuple[jax.typing.ArrayLike, np.ndarray, int, np.ndarray]):\n",
    "                - value (jax.typing.ArrayLike): The original value estimate.\n",
    "                - choice_p (jnp.ndarray): The choice probabilities.\n",
    "                - choice (int): The chosen action.\n",
    "                - choice_array (jnp.ndarray): The chosen action in one-hot format.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get choice probabilities\n",
    "    choice_p = softmax(value[None, :], temperature).squeeze()\n",
    "\n",
    "    # Get choice\n",
    "    choice = choice_from_action_p(key, choice_p)\n",
    "\n",
    "    # Convert it to one-hot format\n",
    "    choice_array = jnp.zeros(n_actions, dtype=jnp.int16)\n",
    "    choice_array = choice_array.at[choice].set(1)\n",
    "\n",
    "    # Get the outcome and update the value estimate\n",
    "    updated_value, prediction_error = asymmetric_rescorla_wagner_update(\n",
    "        value,\n",
    "        choice_array,\n",
    "        outcome,\n",
    "        alpha_p,\n",
    "        alpha_n,\n",
    "    )\n",
    "\n",
    "    return updated_value, (value, choice_p, choice_array, prediction_error)\n",
    "\n",
    "asymmetric_rescorla_wagner_update_choice = jax.jit(asymmetric_rescorla_wagner_update_choice, static_argnums=(5,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can try running it again..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Value: [0.05000001 0.5        0.55       0.5        0.05000001]\n",
      "Choice probabilities: [0.2 0.2 0.2 0.2 0.2]\n",
      "Choice: [0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the value, outcome, choices, and learning rates\n",
    "value = np.ones(5) * 0.5\n",
    "outcome = np.array([1.0, 0.0, 1.0, 0.0, 1.0])\n",
    "alpha_p = 0.1\n",
    "alpha_n = 0.9\n",
    "temperature = 0.5\n",
    "\n",
    "# Get a random key\n",
    "key = jax.random.PRNGKey(0)\n",
    "\n",
    "# Call the function\n",
    "updated_value, (value, choice_p, choice_array, prediction_error) = asymmetric_rescorla_wagner_update_choice(\n",
    "    value, outcome, alpha_p, alpha_n, temperature, 5, key\n",
    ")\n",
    "\n",
    "# Print the results\n",
    "print(f\"Updated Value: {updated_value}\")\n",
    "print(f\"Choice probabilities: {choice_p}\")\n",
    "print(f\"Choice: {choice_array}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the function has chosen action number `2` (0-indexed), and this is the only action that has had its value updated."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "windows_general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
